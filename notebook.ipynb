{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.recommenders import movie_lens_fairness_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MovieLensFairness-v0', slate_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1.], (25,), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_id', 'sex', 'age', 'occupation', 'zip_code'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01785714, 0.1       , 0.60660607, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([3883 3883 3883])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_slate = env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1991, 3159, 1504])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_id', 'sex', 'age', 'occupation', 'zip_code'])\n"
     ]
    }
   ],
   "source": [
    "state, reward, done, info = env.step(random_slate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01785714, 0.1       , 0.60660607, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 4.73380258, 0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822535055434238"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  agents.recommenders.recsys.manager import MovieLensFairnessManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = MovieLensFairnessManager(slate_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.recommenders.recsys.rl.base_agent import RandomAgent\n",
    "from agents.recommenders.recsys.rl.dqn import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_agent = RandomAgent(action_space=manager.env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dev/ml-fairness-gym-recism/notebook.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B68.183.134.193/home/dev/ml-fairness-gym-recism/notebook.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m dqn_agent \u001b[39m=\u001b[39m DQNAgent(env\u001b[39m.\u001b[39;49maction_space, \u001b[39m64\u001b[39;49m, \u001b[39m128\u001b[39;49m)\n",
      "File \u001b[0;32m~/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py:33\u001b[0m, in \u001b[0;36mDQNAgent.__init__\u001b[0;34m(self, input_size, output_size, hidden_size, network_update_frequency, initial_exploration_probability, decay_rate, minimum_exploration_probability, buffer_size, buffer_burn_in, batch_size, discount_factor, learning_rate, random_state)\u001b[0m\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=17'>18</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=18'>19</a>\u001b[0m     input_size: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=30'>31</a>\u001b[0m     random_state: RandomState \u001b[39m=\u001b[39m RandomState(seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m),\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=31'>32</a>\u001b[0m ):\n\u001b[0;32m---> <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=32'>33</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=33'>34</a>\u001b[0m         initial_exploration_probability,\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=34'>35</a>\u001b[0m         decay_rate,\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=35'>36</a>\u001b[0m         minimum_exploration_probability,\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=36'>37</a>\u001b[0m         random_state,\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=37'>38</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=39'>40</a>\u001b[0m     architecture \u001b[39m=\u001b[39m sequential_architecture(\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=40'>41</a>\u001b[0m         input_size, hidden_size, output_size\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=41'>42</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///home/dev/ml-fairness-gym-recism/agents/recommenders/recsys/rl/dqn.py?line=42'>43</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork \u001b[39m=\u001b[39m DeepQNetwork(learning_rate, architecture, discount_factor)\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "dqn_agent = DQNAgent(env.action_space, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad0941184a43b957bc6ae529f31f5d5f974603eadeee465886be5ed651cfe48e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('catalyst_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
